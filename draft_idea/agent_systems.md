Here is my transcript on automatic research agents, please formalize it aka get rid of the gramatical errors and add diagrams etc "
Alrighty, this is a transcription to basically Define the architecture. Of. Agent systems. Or Asian services that are necessary, as well as to flow among them in order to complete the task of. Generating research automatically. Okay? Now, do bear in mind that this is preliminary could be expanded, and it also doesn't.

Um. It. It will cover just three subsections for three services by themselves. The names may vary upon application. But the main idea holds. For example, the first system is called hypothesis system, but in the code, it's called initial research agent. So, for example, keep that in mind. Nonetheless, the initial research agent, which is the hypothesis system, is one of the three main systems in order to be able to.

Programmatically do research. The idea behind it is that we get as an input. A project right, and all of the information associated with the project it's made at data, as well as metadata for experiments that are associated with it, and just like titles or anything of the literature that already is associated with the project, if any, as well, as well as notes, uh, in the notes, will be in full detail as well that that is one exception.

That one is full detail. Uh, another thing that's an exception. The paper will be full detail, like the full raw content will be presented to the. To the system. Uh, so basically, we, that's the first step. That's the ingestion. Well, the manager intakes, what happens later, is that we feed that to the literature review, um, agent.

In this literature review, agent is in charge of taking in. The. Information that got that has the input, right, that input, and then its whole purpose is to analyze what information we have. With literature. If we already have, we don't need to check more, but basically, what literature would be useful, or we need in order to answer this.

Basically, its job is that it says, if you gave. A research assistant, the task of conducting a research review, a literature review that's the same process in this specific step. It will take a while. It's supposed to continue until it is satisfied that it has enough research or literature review without being too excessive, um, to cover the question that the paper is projecting, right, like the main find that we're trying to articulate?

Once it, does that research review the way that it's going to do, it is through its tool use. It should have access to be able to search across sources, be able to get titles but read abstracts, or just basically read content if necessary. It generally should stick to reading abstracts, um, all together.

Every time that I find something that is satisfied, it creates basically an object that you've constructed that anytime it wants to. Add any literature that it does find, uh, from its searches into the into the project. It is instructed to add. Basically. To the project, and then once it satisfied once it finishes.

We then run it through a summary, a literature summary. The literature summary is interesting because the literature summary basically.


Mix in all the literature.


It takes in all the abstracts right, and for now, we only work with abstracts for this part, and what we do is that we grab the project information and the paper. All of the abstracts for the literature that was approved. And from that, we generate a literature review, basically, where we State how each paper relates to the question, how it may help, how is, like, what findings are necessary, where each paper helps, what, Etc, and what do they not cover that? Our question does want to cover, right? Um, basically died. And we save that as a note. That's a that's a special point on the architecture. We save the final, um. Review that this other agent, which is the literature summarizer, generates as a note objects for the. For the project. And then we pass to the next agent, which is the hypotheses generation agent and the hypothesis generation agent is special. It will take in.

All, uh, and this one, especially because it will take. The project overview again, which is just project the full paper content. Um, then, just like the inside of hypotheses, if any, that already exist, right, it needs to. It needs to see those, right? Just like the basis of the description, title, and Status, if anything, right, if it doesn't have a status, you just say not attempted, right? But or whatever it's fit based on the, uh, on the architecture? However, um, it's whole job and purpose is to. Think recent based on that literature review based on the main idea based on the paper content, if any, to bear in mind if the paper has no content right, then we specif we just mentioned. The paper has no content at the moment. Like, we're just starting right, and this goes for anything in the processes. And then, basically, we generate a set of hypotheses. And here we value quality over quantity. We generated a set of hypotheses that, ideally, are questions that should arise based on the literature review based on general knowledge that we have right. And based on the main premise of what is the project trying to solve, right? Like, what's the new question? We make hypotheses to test among them, and if we. Are able to answer them provider. If we do more research and we answer them all together, ideally it should be a inclusive set where if we answer or the answers to those hypotheses should be the answer to the main project, right? And, uh, it's just questions that we need answers to.

The next step. The the that we partake is on. Testing. Basically. Your testing system, and this is optional because there could be a fourth system that goes in between the testing system and the hypothesis system, which is called the initial draft. And basically what this part should do is? If, and this is important. It's only if there is no content for the paper written. Right, we take the project idea. We take the hypothesis generated into literature summary, and we basically ask the system write a draft that should be able to basically answer the information here.


And then


From that. Well, basically, it's not like answering the paper. It's not like writing the paper with assumptions, right? It's just writing a paper kind of, like in it, we're posting this question, so we just write the abstract. We don't write it in full. We write the abstract of what we want, and we do a small section of what is said that we already know, right? And that's actually pretty important. We should like, write what we already know on that initial section of review. Then the testing system comes into play. The testing system gets the project, right? And basically gets the packet of the project hypotheses and the and the paper right. At this point, everything should have a paper, even if it didn't before, because we passed it through the previous step. And it goes to a very simple aspect where it grabs. Each hypothesis. Right, and it's interesting because it only kind of like gets all the information right as an input. But then we go into, like a forward Loop. Well, it's actually not a for Loop. We should do this in parallel, right? Um. To speed up things. So, in parallel, it grabs each hypothesis and per each hypothesis. We pass on all of the project information to an agent called the research agent. So, again, the paper, the project info, and the hypothesis that we're working on, right, none of the others. It doesn't have that context yet, and its whole task is to ask. Search, if any, do you do you need? For this specific. Question that we're trying to find, right? Um, basically, find the background information so that we can then answer the hypothesis. That's a whole step of this one, and it should play with tools from. Restriction papers, tools, as well as. Well, actually, this one should primarily only be yeah, for both actually should be both. And I think it shouldn't be in parallel. Let's keep it instead of parallel. Let's skip it all in, like series, uh, so hypothesis get tested on a for Loop. As they go through the testing process, right? We give the researcher the ability to. Check with, uh, the web, as well as the ability to check.

With the journals right with the search functions that we already have available to the agents. Okay. And then once that's done. Once we have the research, we pass to the next section and the next section. Is should be given. The hypotheses. The Associated research in a structure format, obviously, that the agent was able to gather and create. The paper and the project information. As well as any experiments, if any already exist. And then it should be asked a simple question. This, it's a simple agent. This agent is a. Do we need simulation agent and its whole purpose is to Output a Boolean? Yes or no, and with extra information as well. Why, yes, why? No? Basically, the question is, do we need or? Yeah, I think the word should be. Do we need any simulation or code for the specific hypothesis? Like, can we test? Um. Can we test this hypothesis or is there a way? I think that's a better question. It's like, is there a way or any procedure that we can do with just raw python in order to be able to test this hypothesis and then also mention what libraries you need. It's kind of like the output, so basically, if yes, then it's not optional. It should be able to tell us. Uh, well, actually, not even this step. I think it's only just for now, and the reason that's all I should do, like, yes, we can test with python and simulation for something of this kind because we can run blah, blah, blah, blah, or no. The hypothesis does not rely at all with anything that can be tested numerically through python, right? That's kind of like the two outputs. Yes, then we pass it to another agent, which is the. Uh, simulation, creation and execution agent, and what this one is task to do is basically given the hypothesis, given the plan and the project information we provide project information and research that could give it everything to this one. We ask it. Please create an experiment or a set of an experiments and run them and see the values of those experiments after you run them and fix accordingly until you're able to get an answer. It doesn't matter if it fits or doesn't fit the hypothesis as long as you get an answer. Experiments that you're trying to do for the hypothesis that we are testing, and that's his whole job. Just to create the python, run it or the experiments run it. See if the results didn't give a error in code. And um, also important, is that when it creates the?


Creates. But yeah, that's


His whole job. That's all I should do. After we get that right, um, either they say, yes or no. If they say yes, we get the information of the simul of the experiment. Once that's done, if no, we still proceed point. Is that those two conclude to the hypothesis answer? Agent and what this one does is that it craps again all the paper, um, like information or the abstract right, and the information that we have, then it grabs the hypotheses that we're working on and the research that we did. And, if available, the simulations experiments that we ran and the results, right? The hypothesis with? Yes, no, or inconclusive, right? So in reasoning, of course. Like, it's not just yes, or like, we get the base value of, yes, no or inconclusive, or like the ones that we have available to our system, right, which is in models that buy. However. Should be able to answer it and with an explanation, right, or with some conditionals or anything of that kind and basically get a solution right to the hypothesis. We repeat that for each hypothesis, and that is the conclusion of the testing system. Should we have this? We should be good enough to go to the next system, which is the compilation agent system, and in contrast to the testing system agent or the initial research slash hypothesis system or. The other one is that this one takes in all the information of the project, the hypotheses, all of them, their status. And it actually presents the hypothesis in full. The experiments in full as well? The project, the paper in full, the literature review. Um, just like the list of the names and then the literature summary. And then it's asked to generate. Basically, um, diffs to the new paper. Um, and it should be able to generate. Um, a food list of fifths basically to to the new paper, um. And, and that's it. So, those diffs? Are to be applied to to the paper, and it's important that we emphasize on diff, so diffs differences. Because we do not necessarily want the the model to Output. The full paper every single time it wants to make a change or all of the changes at once, right? We should be able to have, like? Differential engine where a system. Given the paper, right? The model can say I want to change this paragraph. I want to change this other paragraph. To this, or I want to add a specific graph to here I want to add, Etc to here, etc, etc, and that's it, and we grab the output basically. Once we compiled those differences into now, what we have is the final paper, and that is the full cycle of three. Well, four systems for a genetic systems all together that allows us to do research." and make it al in markdown